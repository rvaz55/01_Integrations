{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18904f0-3108-4144-8132-e3caffe4666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the 'os' module in Python to access the OperatingSystem and retrieve the API_KEY\n",
    "#More info on the OS module: https://docs.python.org/3/library/os.html\n",
    "#Create temporary EnvVar: Link explaining how to creat new environment vars: https://www.geeksforgeeks.org/python-os-environ-object/#\n",
    "#Persistent envir_var: use the .env file and then add it to .gitignore\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables\n",
    "import os\n",
    "OPENAPI_AI_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#print(f'OPENAPI_AI_KEY: {OPENAPI_AI_KEY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17adf93-bbe5-4d52-abb9-5bb6b2c5a690",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In this exercise we use the HNLoader to load the comments made on a post:\n",
    "\n",
    "#To use a HNLoader you must first import the class from LangChain:\n",
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a439f85-eea5-46b7-ae48-9e843dfcb053",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For HNLoader we need to pass in the URL of a Hacker-New's comment-page\n",
    "\n",
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=38793206\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86144c3-52b0-40f9-9545-51fb1f86f536",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Here the comments are loaded into the 'data' object\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fca496-212b-48d9-8bba-9d73f0c07aa6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#View contents of the first comment\n",
    "#print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4cd10f-ebe6-4858-971e-34c6f5a2e570",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://news.ycombinator.com/item?id=38793206', 'title': 'Cold-blooded software'}\n"
     ]
    }
   ],
   "source": [
    "#The metadata contains the URL-Source and the title of the post\n",
    "print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f319436b-6fad-4e14-b09d-67e785f73e7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Combine HNLoader with a model call using the 'human-to-chat' template and the 'chat-prompt chat' template.\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da09077d-882b-458b-9cc5-3dd74641a26f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Also need to import models from LangChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ef49d0-ee5e-4ab9-987a-14ac277e4d7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create instance of the human prompt\n",
    "#human_prompt = HumanMessagePromptTemplate.from_template(\"Please give me a short summary of the following HackerNews comment: \\n {comment}\")\n",
    "\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"Please give me a short summary explaining the recurrent points made in the comments: \\n {comment}. \")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363d2aba-35e6-4cf5-8213-0e5e0851104d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Then create instance of the chat prompt and pass in the human_prompt\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8a77a7-afa8-40be-b8cc-73de9f027d90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Then create instance of an OpenAI chat-model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Docs on ChatOpenAI() are: https://python.langchain.com/docs/integrations/chat/openai\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAPI_AI_KEY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "#Then create instance of an OpenAI chat-model\n",
    "#Docs on ChatOpenAI() are: https://python.langchain.com/docs/integrations/chat/openai\n",
    "model = ChatOpenAI(api_key=OPENAPI_AI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3de5fda-9694-40d3-bf63-b81388272e0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Pass in the chat-prompt to the model. Then format the chat-prompt and store the output within a 'result' var\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(chat_prompt\u001b[38;5;241m.\u001b[39mformat_prompt(comment \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\u001b[38;5;241m.\u001b[39mto_messages())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Pass in the chat-prompt to the model. Then format the chat-prompt and store the output within a 'result' var\n",
    "result = model(chat_prompt.format_prompt(comment = data[0].page_content).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c56c01a-42a9-40c5-ae23-a4fb5ebcd97d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the comments, the main recurrent points are:\\n\\n1. Python is not a good example of stable software because it has constant breaking changes in both runtime and tooling.\\n2. The author still has to use Python 2, which has reached its end of life, indicating the lack of backwards compatibility.\\n3. Other programming languages like Go or Java are better examples of maintaining compatibility over time, as code written 10 years ago still runs fine with modern tooling.\\n4. Perl is mentioned as an even better example, as code written 30 years ago still runs without issues.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then ask the OpenAI model to resolve the request written on line 17\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410fd91-8a51-4826-8afd-542028fa3a6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c32ae-cb50-42ca-ad36-a4410546ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850efa20-7678-403f-bc8f-81c274f64835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898037e-a22c-4701-a05c-668fda4232fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a8119-4139-4f2a-a618-544c82179290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb038a0-9ddb-45dc-a870-f896c4a957ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
