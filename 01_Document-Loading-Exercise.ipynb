{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcded1a6-2430-4707-a78c-c82f4c5ee6fc",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "#  Document Loading Exercise \n",
    "\n",
    "## Answering a Single Question\n",
    "\n",
    "Using the Wikipedia Document Loader Integration,can you make a function that accepts a famous historical figure name and a question about them, and then uses a ChatModel to answer questions with the additional context? Notice how in our example, the query doesn't mention the famous person. Keep in mind there are many potential ways to solve this problem!\n",
    "\n",
    "## Requirements\n",
    "- Function must accept *'name'* of historical figure\n",
    "- Function must accept *'question'* regarding the historical figure\n",
    "- Program must use ChatModel to respond to the input-question\n",
    "\n",
    "## Subtasks\n",
    "- Load data from wiki by calling instance of `WikipediaLoader`\n",
    "- Instantiate a `HumanMessagePromptTemplate` and pass in the *'question'*, *'name'* and wiki data\n",
    "- Open connection to OpenAI model by instantiating `ChatOpenAI`\n",
    "- Submit the prompt to the `ChatOpenAI` instance\n",
    "- Get response from the `ChatOpenAI` instance\n",
    "\n",
    "## Notable notes:\n",
    "- A *prompt* for a language model is a set of instructions or input provided by a user to guide the model's *response*, helping it understand the context and generate relevant and coherent language-based *output*, such as answering questions, completing sentences, or engaging in a conversation.\n",
    "- LangChain provides different types of <a href=\"https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/msg_prompt_templates\">  `MessagePromptTemplate` </a>. The most commonly used are `AIMessagePromptTemplate`, `SystemMessagePromptTemplate` and `HumanMessagePromptTemplate` , which create an AI message, system message and human message respectively.\n",
    "- The `ChatMessagePromptTemplate` can be used with models that support taking chat messages with an arbitrary role. For example, asking a question and then submitting the role '5th grader' to ask the LLM to craft a response that can be understood by a '5th grader'\n",
    "- <a href=\"https://python.langchain.com/docs/integrations/document_loaders/wikipedia\"> LangChain Documentation for WikipediaLoader </a>\n",
    "- <a href=\"https://pypi.org/project/wikipedia/\"> Documentation for `Wikipedia` package listed on PyPi.org </a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "244f42d8-2349-446e-a1c2-ae4b8d3ee38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run line below on terminal (sans #)\n",
    "#pip3 install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18dc1a5c-8c4f-45d3-b0c3-a40b1dc9dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import templates, tools and other packages\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "187a6057-324d-4bab-b27c-cb31ac81406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables\n",
    "import os\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "#Function to grab data from Wiki\n",
    "#def get_Wiki_docs()\n",
    "\n",
    "    #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a539244-89c6-4019-8608-1cdf51ba1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the question\n",
    "def answer_question_about(person_name,question):\n",
    "    \n",
    "    #Use the Wikipedia Document Loader to help answer questions about someone, insert it as additional helpful context.\n",
    "\n",
    "    #Create instance of 'WikipediaLoader' and pass in the 'question' and limit the # of returned docs; a 'doc' is a paragraph\n",
    "    wikiQuery = WikipediaLoader(query=person_name, load_max_docs=2).load()\n",
    "    wikiData = wikiQuery[0].page_content\n",
    "\n",
    "    #Create the 'template' that needs to be passed to HumanMessagePromptTemplate\n",
    "    input_template = f'Please answer this question, {question} about {person_name} using this context: {wikiData}'\n",
    "\n",
    "    #Pass 'template' to 'human_prompt'\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(input_template)\n",
    "\n",
    "    #Pass the 'human_prompt' to the AI-chatmodel\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "\n",
    "    #Create instance of the systemTemplate and pass in the human_prompt\n",
    "    #ai_prompt = SystemMessagePromptTemplate.from_template([human_prompt])\n",
    "    #docs = WikipediaLoader(query=\"HUNTER X HUNTER\", load_max_docs=2).load()\n",
    "    #print(ai_prompt)\n",
    "\n",
    "    #Create instance of OpenAI mUnicodeTranslateError\n",
    "    ai_model = ChatOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    #Format the chat_prompt and pass in the 'question' and 'wikiData' params \n",
    "    #Lastly, send the ai_model the prompt; prompt must be a list of messages\n",
    "    result = ai_model(chat_prompt.format_prompt(question=question,\n",
    "                                                document=wikiData, #).to_messages())\n",
    "                                                person_name=person_name).to_messages())\n",
    "    print(result)\n",
    "    return result.content #answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c852633-9c93-440c-9530-1b5640000b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3a43963-57d4-44c5-8d28-b6164b2c0b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Claude Shannon was born on April 30, 1916.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claude Shannon was born on April 30, 1916.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question_about(\"Claude Shannon\",\"When was he born?\")\n",
    "# Claude Elwood Shannon was born on April 30, 1916."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9074e58-b4af-4a21-a503-a0c58621a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdddee8-d449-4bfb-a0f3-d8466a65afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68fc96-90ea-4197-ac50-f7520b93ed95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d3058-47c6-4062-8e63-6fbc70303dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860d97f-673c-4676-b52c-ae21d4c18bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec899a-b313-4643-bb20-73dca6732ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
